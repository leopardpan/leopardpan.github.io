---
layout: post
title: 建立深度学习Ubuntu实验环境
date: 2023-04-27
description: "建立深度学习Ubuntu实验环境"
tag: Python
---
## 建立深度学习Ubuntu实验环境

```shell
hugo@hugo-virtual-machine:~$ mkdir my_tensorflow
hugo@hugo-virtual-machine:~$ cd my_tensorflow/
hugo@hugo-virtual-machine:~/my_tensorflow$ python3.10 -m venv vision
hugo@hugo-virtual-machine:~/my_tensorflow$ source venv/bin/activate
(vision) hugo@hugo-virtual-machine:~/my_tensorflow$ pip install --upgrade pip
(vision) hugo@hugo-virtual-machine:~/my_tensorflow$ pip install tensorflow tensorflow-gpu
```

python -m表示运行一个模块，venv表示虚拟环境，vision表示虚拟环境的名字，source表示激活虚拟环境，pip install --upgrade pip表示更新pip，pip install tensorflow tensorflow-gpu表示安装tensorflow和tensorflow-gpu。

发现tensorflow-gpu安装失败，原因是没有安装CUDA，所以需要先安装CUDA。

## 安装CUDA

打开[https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local)，选择CUDA Toolkit 12.1，选择Linux，选择x86_64，选择Ubuntu，选择22.04，选择runfile(local)，安装向导如下。

```shell
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
```

## 安装CUDA Deep Neural Network (cuDNN)

打开[https://developer.nvidia.com/rdp/cudnn-archive](https://developer.nvidia.com/cudnn)，选择cuDNN 8.2.4 for CUDA 12.1，选择cuDNN Library for Linux，选择x86_64，下载cuDNN Library for Linux (x86_64)。

```shell


## 安装Keras

```shell
git clone https://github.com/keras-team/keras.git
cd keras
python setup.py install
```

现在可以尝试运行一下一个Keras脚本，比如说MNIST的例子。

```shell
python examples/mnist_mlp.py
```

可以在~/.keras/heras.json找到Keras的配置文件，可以修改backend（后端）为tensorflow或者theano或者cntk.

运行脚本时候，可以在shell窗口中监控GPU利用率。

```shell
watch -n 5 NVIDIA-smi -a --display=utilization
```

watch表示监控，-n 5表示每5秒刷新一次，NVIDIA-smi表示NVIDIA System Management Interface，-a表示显示所有信息，--display=utilization表示显示GPU利用率。

```shell
{
    "image_data_format": "channels_last",
    "epsilon": 1e-07,
    "floatx": "float32",
    "backend": "tensorflow"
}
```

## 安装OpenCV

```shell
sudo apt-get install libopencv-dev python-opencv
```

## 安装Jupyter

```shell
pip install jupyter
```

## 映射远端端口到本地


 **第一步** ，在远程Terminal中启动[Jupyter](https://so.csdn.net/so/search?q=Jupyter&spm=1001.2101.3001.7020) Notebook：

```python
jupyter notebook --no-browser --port=8889
```


```shell
ssh -L 8888:localhost:8888 remote_user@remote_host
```

这段表示将远端的8888端口映射到本地的8888端口。remote_user表示远端的用户名，remote_host表示远端的主机名或者IP地址。

然后在本地运行jupyter notebook，就可以在本地访问远端的jupyter notebook了。

```shell
jupyter notebook
```

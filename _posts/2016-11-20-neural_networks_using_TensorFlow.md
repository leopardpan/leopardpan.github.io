---
layout: post
title: ä½¿ç”¨ TensorFlow å®ç°ç¥ç»ç½‘ç»œ
date: 2016-11-20 
tags: æœºå™¨å­¦ä¹   
---

## ä»‹ç»

ã€€ã€€ä¸€ç›´å…³æ³¨ `æ•°æ®ç§‘å­¦` ã€ `æœºå™¨å­¦ä¹ ` çš„åŒå­¦ï¼Œä¸€å®šä¼šç»å¸¸çœ‹åˆ°æˆ–å¬åˆ°å…³äº `æ·±åº¦å­¦ä¹ ` å’Œ `ç¥ç»ç½‘ç»œ` ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœä½ å¯¹ `æ·±åº¦å­¦ä¹ ` æ„Ÿå…´è¶£ï¼Œä½†å´è¿˜æ²¡æœ‰å®é™…åŠ¨æ‰‹æ“ä½œè¿‡ï¼Œä½ å¯ä»¥ä»è¿™é‡Œå¾—åˆ°å®è·µã€‚ 

ã€€ã€€åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»‹ç» `TensorFlow` ,Â å¸®ä½ äº†è§£ `ç¥ç»ç½‘ç»œ` çš„å®é™…ä½œç”¨ï¼Œå¹¶ä½¿ç”¨ `TensorFlow` æ¥è§£å†³ç°å®ç”Ÿæ´»ä¸­çš„é—®é¢˜ã€‚Â è¯»è¿™ç¯‡æ–‡ç« å‰ï¼Œéœ€è¦çŸ¥é“ `ç¥ç»ç½‘ç»œ` çš„åŸºç¡€çŸ¥è¯†å’Œä¸€äº›ç†Ÿæ‚‰ç¼–ç¨‹ç†å¿µï¼Œæ–‡ç« ä¸­çš„ä»£ç æ˜¯ä½¿ç”¨ `Pyhton` ç¼–å†™çš„ï¼Œæ‰€ä»¥è¿˜éœ€è¦äº†è§£ä¸€äº› `Python` çš„åŸºæœ¬è¯­æ³•ï¼Œæ‰èƒ½æ›´æœ‰åˆ©å¯¹äºæ–‡ç« çš„ç†è§£ã€‚                  
                           

<div align="center">
	<img src="/images/posts/tfimg/logo.jpg" height="300" width="500">  
</div> 


### ç›®å½•

* [ä»€ä¹ˆæ—¶å€™åº”ç”¨ç¥ç»ç½‘ç»œï¼Ÿ](#When-to-apply-neural-net)
* [é€šå¸¸ç¥ç»ç½‘ç»œèƒ½è§£å†³çš„é—®é¢˜](#solve-problems)
* [äº†è§£å›¾åƒæ•°æ®å’Œä¸»æµçš„åº“æ¥è§£å†³é—®é¢˜](#popular-libraries)
* [ä»€ä¹ˆæ˜¯ TensorFlowï¼Ÿ](#What-is-TensorFlow)
* [TensorFlowÂ ä¸€ä¸ªÂ å…¸å‹Â çš„Â â€œÂ æµÂ â€](#A-typical-flow)
* [åœ¨ TensorFlow ä¸­å®ç° MLP](#MLP)
* [TensorFlow çš„é™åˆ¶](#Limitations-of-TensorFlow)
* [TensorFlow ä¸å…¶ä»–åº“](#vs-libraries)
* [ä»è¿™é‡Œå»å“ªé‡Œï¼Ÿ](#Where-to-go-from-here)


### <a name="When-to-apply-neural-net"></a>ä»€ä¹ˆæ—¶å€™ç”¨ç¥ç»ç½‘ç»œï¼Ÿ

ã€€ã€€`ç¥ç»ç½‘ç»œ` å·²ç»åœ¨ç›¸å½“ä¸€æ®µæ—¶é—´æˆä¸ºæœºå™¨å­¦ä¹ ä¸­çš„ç„¦ç‚¹ã€‚Â å¯¹äº `ç¥ç»ç½‘ç»œ` å’Œ `æ·±åº¦å­¦ä¹ ` ä¸Šè¿™é‡Œæœ‰æ›´è¯¦ç»†çš„è§£é‡ŠÂ [ç‚¹å‡»é˜…è¯»](https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/)Â ã€‚Â å…¶ â€œæ›´æ·±â€ çš„åŠŸèƒ½åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰å–å¾—å·¨å¤§çš„çªç ´ï¼Œå¦‚å›¾åƒè¯†åˆ«ï¼Œè¯­éŸ³å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚

ã€€ã€€ä¸»è¦çš„é—®é¢˜åœ¨äºå¦‚ä½•ç”¨å¥½ `ç¥ç»ç½‘ç»œ` ï¼Ÿç°åœ¨ï¼Œæ¯å¤©éƒ½ä¼šæœ‰è®¸å¤šæ–°å‘ç°ï¼Œè¿™ä¸ªé¢†åŸŸå°±åƒä¸€ä¸ªé‡‘çŸ¿ï¼Œä¸ºäº†æˆä¸ºè¿™ä¸ª â€œæ·˜é‡‘çƒ­â€ çš„ä¸€éƒ¨åˆ†ï¼Œå¿…é¡»è®°ä½å‡ ä»¶äº‹ï¼š

* **é¦–å…ˆï¼Œ`ç¥ç»ç½‘ç»œ` éœ€è¦æœ‰æ˜ç¡®å’Œç¿”å®çš„æ•°æ®ï¼ˆä¸»è¦æ˜¯å¤§æ•°æ®ï¼‰è®­ç»ƒ**ï¼ŒÂ è¯•ç€æƒ³è±¡ `ç¥ç»ç½‘ç»œ` ä½œä¸ºä¸€ä¸ªå­©å­ï¼Œå®ƒä¸€å¼€å§‹ä¼šè§‚å¯Ÿå®ƒçˆ¶æ¯èµ°è·¯ï¼Œç„¶åå®ƒè¯•å›¾è‡ªå·±èµ°ï¼Œæ¯ä¸€æ­¥å°±åƒå­¦ä¹ æ‰§è¡Œä¸€ä¸ªç‰¹å®šçš„ä»»åŠ¡ã€‚Â å®ƒå¯èƒ½ä¼šå¤±è´¥å‡ æ¬¡ï¼Œä½†ç»è¿‡å‡ æ¬¡å¤±è´¥çš„å°è¯•ï¼Œå®ƒå°†ä¼šå¦‚ä½•èµ°è·¯ã€‚æ‰€ä»¥éœ€è¦ä¸ºå­©å­æä¾›æ›´å¤šçš„æœºä¼šï¼Œå¦‚æœä¸è®©å®ƒèµ°ï¼Œå®ƒå¯èƒ½æ°¸è¿œä¸ä¼šå­¦ä¹ å¦‚ä½•èµ°è·¯ã€‚

* **ä¸€äº›äººä¼šåˆ©ç”¨ `ç¥ç»ç½‘ç»œ` è§£å†³å¤æ‚çš„é—®é¢˜ï¼Œå¦‚å›¾åƒå¤„ç†ï¼Œ** Â `ç¥ç»ç½‘ç»œ` å±äºä¸€ç±»ä»£è¡¨å­¦ä¹ çš„ç®—æ³•ï¼Œè¿™äº›ç®—æ³•å¯ä»¥æŠŠå¤æ‚çš„é—®é¢˜åˆ†è§£ä¸ºç®€å•çš„å½¢å¼ï¼Œä½¿ä»–ä»¬æˆä¸ºå¯ä»¥ç†è§£çš„ï¼ˆæˆ–Â â€œå¯è¡¨ç¤ºâ€ï¼‰ï¼Œå°±åƒåå’½é£Ÿç‰©ä¹‹å‰çš„å’€åš¼ï¼Œè®©æˆ‘ä»¬æ›´å®¹æ˜“å¸æ”¶å’Œæ¶ˆåŒ–ã€‚è¿™ä¸ªåˆ†è§£çš„è¿‡ç¨‹å¦‚æœä½¿ç”¨ä¼ ç»Ÿçš„ç®—æ³•æ¥å®ç°ä¹Ÿå¯ä»¥ï¼Œä½†æ˜¯å®ç°è¿‡ç¨‹å°†ä¼šå¾ˆå›°éš¾ã€‚

* **é€‰æ‹©é€‚å½“ç±»å‹çš„ `ç¥ç»ç½‘ç»œ` ï¼Œæ¥è§£å†³é—®é¢˜ï¼Œ** Â æ¯ä¸ªé—®é¢˜çš„å¤æ‚æƒ…å†µéƒ½ä¸ä¸€æ ·ï¼Œæ‰€ä»¥æ•°æ®å†³å®šä½ è§£å†³é—®é¢˜çš„æ–¹å¼ã€‚Â ä¾‹å¦‚ï¼Œå¦‚æœé—®é¢˜æ˜¯åºåˆ—ç”Ÿæˆçš„é—®é¢˜ï¼Œ`é€’å½’ç¥ç»ç½‘ç»œ` æ›´åˆé€‚ã€‚å¦‚æœå®ƒæ˜¯å›¾åƒç›¸å…³çš„é—®é¢˜ï¼Œæƒ³æ›´å¥½åœ°è§£å†³å¯ä»¥é‡‡å– `å·ç§¯ç¥ç»ç½‘ç»œ`ã€‚

* **æœ€åæœ€é‡è¦çš„å°±æ˜¯ `ç¡¬ä»¶` è¦æ±‚äº†ï¼Œç¡¬ä»¶æ˜¯è¿è¡Œ `ç¥ç»ç½‘ç»œ` æ¨¡å‹çš„å…³é”®ã€‚**Â ç¥ç»ç½‘è¢«Â â€œå‘ç°â€Â å¾ˆä¹…ä»¥å‰ï¼Œä»–ä»¬åœ¨è¿‘å¹´æ¥å¾—åˆ°æ¨å´‡çš„ä¸»è¦çš„åŸå› å°±æ˜¯è®¡ç®—èµ„æºæ›´å¥½ï¼Œèƒ½æ›´å¤§å‘æŒ¥å®ƒçš„å…‰èŠ’ï¼Œå¦‚æœä½ æƒ³ä½¿ç”¨ `ç¥ç»ç½‘ç»œ` è§£å†³è¿™äº›ç°å®ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œé‚£ä¹ˆä½ å¾—å‡†å¤‡è´­ä¹°ä¸€äº›é«˜ç«¯çš„ç¡¬ä»¶äº†ğŸ˜†ï¼

### <a name="solve-problems"></a>é€šå¸¸ç¥ç»ç½‘ç»œè§£å†³çš„é—®é¢˜

ã€€ã€€ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ç®—æ³•ã€‚Â å› æ­¤ï¼Œä½œä¸ºæ¯ä¸ª ML ç®—æ³•éƒ½éµå¾ª æ•°æ®é¢„å¤„ç† ã€æ¨¡å‹å»ºç«‹ å’Œ æ¨¡å‹è¯„ä¼° çš„å·¥ä½œæµæµç¨‹ã€‚ä¸ºäº†ç®€æ˜èµ·è§ï¼Œä¸‹é¢åˆ—å‡ºäº†å¦‚ä½•å¤„ç† `ç¥ç»ç½‘ç»œ` é—®é¢˜çš„ TODO åˆ—è¡¨ã€‚

* æ£€æŸ¥å®ƒæ˜¯å¦ä¸º ç¥ç»ç½‘ç»œ ï¼ŒæŠŠå®ƒçœ‹æˆä¸€ä¸ªä¼ ç»Ÿçš„ç®—æ³•é—®é¢˜
* åšä¸€ä¸ªè°ƒæŸ¥ï¼Œå“ªä¸ª ç¥ç»ç½‘ç»œ æ¡†æ¶æœ€é€‚åˆè§£å†³è¿™ä¸ªé—®é¢˜
* å®šä¹‰ ç¥ç»ç½‘ç»œ æ¡†æ¶ï¼Œé€šè¿‡å®ƒé€‰æ‹©å¯¹åº”çš„ ç¼–ç¨‹è¯­è¨€ å’Œ åº“
* å°†æ•°æ®è½¬æ¢ä¸ºæ­£ç¡®çš„æ ¼å¼å¹¶åˆ†æ‰¹åˆ†å‰²
* æ ¹æ®æ‚¨çš„éœ€è¦é¢„å¤„ç†æ•°æ®
* å¢å¼ºæ•°æ®ä»¥å¢åŠ å¤§å°å¹¶åˆ¶ä½œæ›´å¥½çš„è®­ç»ƒæ¨¡å‹
* æ‰¹æ¬¡ä¾›ç»™åˆ° ç¥ç»ç½‘ç»œ
* è®­ç»ƒå’Œç›‘æµ‹ï¼ŒåŸ¹è®­å’ŒéªŒè¯æ•°æ®é›†çš„å˜åŒ–
* æµ‹è¯•ä½ çš„æ¨¡å‹ï¼Œå¹¶ä¿å­˜ä»¥å¤‡å°†æ¥ä½¿ç”¨

ã€€ã€€æœ¬æ–‡å°†ä¸“æ³¨äºå›¾åƒæ•°æ®ï¼Œæˆ‘ä»¬ä» TensorFlow å…¥æ‰‹ã€‚

### <a name="popular-libraries"></a>äº†è§£å›¾åƒæ•°æ®å’Œä¸»æµçš„åº“æ¥è§£å†³é—®é¢˜

ã€€ã€€å›¾åƒå¤§å¤šæ’åˆ—ä¸º 3-D é˜µåˆ—ï¼Œå…·ä½“æŒ‡ é«˜åº¦ã€å®½åº¦ å’Œ é¢œè‰²é€šé“ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨ç”µè„‘æˆªå±ï¼Œå®ƒå°†é¦–å…ˆè½¬æ¢æˆä¸€ä¸ª 3-D æ•°ç»„ï¼Œç„¶åå‹ç¼©å®ƒä¸º '.jpeg' æˆ– '.png' æ–‡ä»¶æ ¼å¼ã€‚

ã€€ã€€è™½ç„¶è¿™äº›å›¾åƒå¯¹äºäººç±»æ¥è¯´å¾ˆå®¹æ˜“ç†è§£ï¼Œä½†è®¡ç®—æœºå¾ˆéš¾ç†è§£å®ƒä»¬ã€‚Â è¿™ç§ç°è±¡ç§°ä¸ºâ€œè¯­ä¹‰ç©ºéš™â€ã€‚æˆ‘ä»¬çš„å¤§è„‘å¯ä»¥çœ‹çœ‹å›¾åƒï¼Œå¹¶åœ¨å‡ ç§’é’Ÿå†…è¯»æ‡‚å®Œæ•´çš„å›¾ç‰‡ã€‚ä½†è®¡ç®—æœºä¼šå°†å›¾åƒçœ‹ä½œä¸€ä¸ªæ•°å­—æ•°ç»„ï¼Œé—®é¢˜æ¥äº†ï¼Œå®ƒæƒ³çŸ¥é“è¿™æ˜¯ä¸€å¼ ä»€ä¹ˆæ ·çš„å›¾åƒï¼Œæˆ‘ä»¬åº”è¯¥æ€ä¹ˆæ ·æŠŠå›¾åƒè§£é‡Šç»™æœºå™¨å®ƒæ‰èƒ½è¯»æ‡‚ï¼Ÿ

ã€€ã€€åœ¨æ—©æœŸï¼Œäººä»¬è¯•å›¾å°†å›¾åƒåˆ†è§£ä¸ºæœºå™¨çš„ â€œå¯ç†è§£â€ æ ¼å¼ï¼Œå¦‚â€œæ¨¡æ¿â€ã€‚ä¾‹å¦‚ï¼Œé¢éƒ¨æ€»æ˜¯å…·æœ‰åœ¨æ¯ä¸ªäººä¸­æœ‰æ‰€ä¿ç•™çš„ç‰¹å®šç»“æ„ï¼Œä¾‹å¦‚çœ¼ç›ï¼Œé¼»å­æˆ–æˆ‘ä»¬çš„è„¸çš„å½¢çŠ¶ã€‚Â ä½†æ˜¯è¿™ç§æ–¹æ³•å°†æ˜¯æœ‰ç¼ºé™·çš„ï¼Œå› ä¸ºå½“è¦è¯†åˆ«çš„å¯¹è±¡çš„æ•°é‡å°†å¢åŠ åˆ°ä¸€å®šé‡çº§æ—¶ï¼Œâ€œæ¨¡æ¿â€ å°†ä¸æˆç«‹ã€‚

ã€€ã€€2012å¹´ä¸€ä¸ªæ·±å±‚ç¥ç»ç½‘ç»œæ¶æ„èµ¢å¾—äº† ImageNet çš„æŒ‘æˆ˜ï¼Œä»è‡ªç„¶åœºæ™¯ä¸­è¯†åˆ«å¯¹è±¡ï¼Œå®ƒåœ¨å³å°†åˆ°æ¥çš„ ImageNet æŒ‘æˆ˜ä¸­ç»§ç»­ç»Ÿæ²»å…¶ä¸»æƒï¼Œä»è€Œè¯æ˜äº†è§£å†³å›¾åƒé—®é¢˜çš„æœ‰ç”¨æ€§ã€‚
äººä»¬é€šå¸¸ä½¿ç”¨å“ªäº› åº“ / è¯­è¨€ æ¥è§£å†³å›¾åƒè¯†åˆ«é—®é¢˜ï¼Ÿ[æœ€è¿‘çš„ä¸€æ¬¡è°ƒæŸ¥](https://www.analyticsvidhya.com/blog/2016/08/deep-learning-path/)ä¸­ï¼Œæœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ åº“ï¼Œæ”¯æŒçš„æœ€å‹å¥½çš„è¯­è¨€æœ‰ Python ï¼Œå…¶æ¬¡æ˜¯ Lua ï¼Œå¯¹ Java å’Œ Matlab æ”¯æŒçš„ä¹Ÿæœ‰ã€‚æœ€æµè¡Œçš„åº“ä¸¾å‡ ä¸ªä¾‹å­ï¼š

* [Caffe](http://caffe.berkeleyvision.org/)
* [DeepLearning4j](http://deeplearning4j.org/)
* [TensorFlow](https://www.tensorflow.org/)
* [Theano](http://www.deeplearning.net/software/theano)
* [Torch](http://torch.ch/)

ç°åœ¨ï¼Œæˆ‘ä»¬äº†è§£äº†å›¾åƒçš„å­˜å‚¨æ–¹å¼ä»¥åŠä½¿ç”¨çš„å¸¸ç”¨åº“ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ `TensorFlow` æä¾›çš„åŠŸèƒ½ã€‚

### <a name="What-is-TensorFlow"></a>ä»€ä¹ˆæ˜¯ TensorFlow ï¼Ÿ

è®©æˆ‘ä»¬ä»å®˜æ–¹å®šä¹‰å¼€å§‹.

ã€€ã€€â€œ`TensorFlow` æ˜¯ä¸€ä¸ªå¼€æºè½¯ä»¶åº“ï¼Œç”¨äºä½¿ç”¨æ•°æ®æµå›¾è¿›è¡Œæ•°å€¼è®¡ç®—ã€‚å›¾ä¸­çš„èŠ‚ç‚¹è¡¨ç¤ºæ•°å­¦è¿ç®—ï¼Œè€Œå›¾è¾¹è¡¨ç¤ºåœ¨å®ƒä»¬ä¹‹é—´ä¼ é€’çš„å¤šç»´æ•°æ®é˜µåˆ—ï¼ˆä¹Ÿç§°ä¸ºå¼ é‡ï¼‰ã€‚Â çµæ´»çš„æ¶æ„å…è®¸æ‚¨ä½¿ç”¨å•ä¸€ API å°†è®¡ç®—éƒ¨ç½²åˆ°æ¡Œé¢ã€æœåŠ¡å™¨æˆ–ç§»åŠ¨è®¾å¤‡ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªçš„ CPU æˆ– GPU ä¸­ã€‚

![](http://www.tensorfly.cn/images/tensors_flowing.gif)     


ã€€ã€€å¦‚æœæ„Ÿè§‰è¿™å¬èµ·æ¥å¤ªé«˜å¤§ä¸Šï¼Œä¸è¦æ‹…å¿ƒã€‚è¿™é‡Œæœ‰æˆ‘ç®€å•çš„å®šä¹‰ï¼Œ`TensorFlow` çœ‹èµ·æ¥æ²¡ä»€ä¹ˆï¼Œåªæ˜¯ numpy æœ‰äº›éš¾ä»¥ç†è§£ã€‚å¦‚æœä½ ä»¥å‰ä½¿ç”¨è¿‡ numpy ï¼Œç†è§£ TensorFlow å°†æ˜¯æ‰‹åˆ°æ“’æ¥ï¼Â numpy å’Œ TensorFlow ä¹‹é—´çš„ä¸»è¦åŒºåˆ«æ˜¯ TensorFlow éµå¾ªæƒ°æ€§ç¼–ç¨‹èŒƒä¾‹ã€‚Â TensorFlow çš„æ“ä½œåŸºæœ¬ä¸Šéƒ½æ˜¯å¯¹ session çš„æ“ä½œï¼Œå®ƒé¦–å…ˆæ„å»ºä¸€ä¸ªæ‰€æœ‰æ“ä½œçš„å›¾å½¢ï¼Œå½“æˆ‘ä»¬è°ƒç”¨ session æ—¶ TensorFlow å°±å¼€å§‹å·¥ä½œäº†ã€‚å®ƒé€šè¿‡å°†å†…éƒ¨æ•°æ®è¡¨ç¤ºè½¬æ¢ä¸ºå¼ é‡ï¼ˆTensorï¼Œä¹Ÿç§°ä¸ºå¤šç»´æ•°ç»„ï¼‰æ¥æ„å»ºä¸ºå¯æ‰©å±•çš„ã€‚Â æ„å»ºè®¡ç®—å›¾å¯ä»¥è¢«è®¤ä¸ºæ˜¯ TensorFlow çš„ä¸»è¦æˆåˆ†ã€‚æƒ³æ›´å¤šåœ°äº†è§£ä¸€ä¸ªè®¡ç®—å›¾å½¢çš„æ•°å­¦ç»“æ„ï¼Œå¯ä»¥é˜…è¯»Â [è¿™ç¯‡æ–‡ç« ](http://colah.github.io/posts/2015-08-Backprop/)Â ã€‚

ã€€ã€€é€šè¿‡ä¸Šé¢çš„ä»‹ç»ï¼Œå¾ˆå®¹æ˜“å°† TensorFlow åˆ†ç±»ä¸ºç¥ç»ç½‘ç»œåº“ï¼Œä½†å®ƒä¸ä»…ä»…æ˜¯å¦‚æ­¤ã€‚å®ƒè¢«è®¾è®¡æˆä¸€ä¸ªå¼ºå¤§çš„ç¥ç»ç½‘ç»œåº“ï¼Œ ä½†å®ƒæœ‰èƒ½åŠ›åšæ›´å¤šçš„äº‹æƒ…ã€‚å¯ä»¥æ„å»ºå®ƒä¸ºå…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå¦‚ å†³ç­–æ ‘ æˆ– k-æœ€è¿‘é‚»ï¼Œä½ å¯ä»¥ä»å­—é¢ä¸Šç†è§£ï¼Œä½ å¯ä»¥åšä¸€åˆ‡ä½ åœ¨ numpy ä¸Šèƒ½åšçš„äº‹æƒ…ï¼æˆ‘ä»¬æš‚ä¸”ç§°å®ƒä¸º â€œå…¨èƒ½çš„ numpyâ€ ã€‚

**ä½¿ç”¨ TensorFlow çš„ä¼˜ç‚¹æ˜¯ï¼š**

* **å®ƒæœ‰ä¸€ä¸ªç›´è§‚çš„ç»“æ„**Â ï¼Œé¡¾åæ€ä¹‰å®ƒæœ‰Â â€œå¼ é‡æµâ€ï¼Œä½ å¯ä»¥è½»æ¾åœ°å¯è§†æ¯ä¸ªå›¾ä¸­çš„æ¯ä¸€ä¸ªéƒ¨åˆ†ã€‚
* **è½»æ¾åœ°åœ¨ cpu / gpu ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—** 
* **å¹³å°çš„çµæ´»æ€§** Â ã€‚å¯ä»¥éšæ—¶éšåœ°è¿è¡Œæ¨¡å‹ï¼Œæ— è®ºæ˜¯åœ¨ç§»åŠ¨ç«¯ã€æœåŠ¡å™¨è¿˜æ˜¯ PC ä¸Šã€‚

### <a name="A-typical-flow"></a>TensorFlow çš„å…¸å‹ â€œæµâ€

ã€€ã€€æ¯ä¸ªåº“éƒ½æœ‰è‡ªå·±çš„â€œå®ç°ç»†èŠ‚â€ï¼Œå³ä¸€ç§å†™å…¶éµå¾ªå…¶ç¼–ç èŒƒä¾‹çš„æ–¹å¼ã€‚Â ä¾‹å¦‚ï¼Œå½“å®ç° scikit-learn æ—¶ï¼Œé¦–å…ˆåˆ›å»ºæ‰€éœ€ç®—æ³•çš„å¯¹è±¡ï¼Œç„¶ååœ¨è®­ç»ƒå’Œæµ‹è¯•é›†ä¸Šæ„å»ºä¸€ä¸ªæ¨¡å‹è·å¾—é¢„æµ‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```python

# define hyperparamters of ML algorithm
clf = svm.SVC(gamma=0.001, C=100.)
# train 
clf.fit(X, y)
# test 
clf.predict(X_test)
```

æ­£å¦‚æˆ‘å‰é¢æ‰€è¯´ï¼ŒTensorFlow éµå¾ªä¸€ç§æ‡’æƒ°çš„æ–¹æ³•ã€‚Â åœ¨ TensorFlow ä¸­è¿è¡Œç¨‹åºçš„é€šå¸¸å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š

* **å»ºç«‹ä¸€ä¸ªè®¡ç®—å›¾**ï¼ŒÂ ä»»ä½•çš„æ•°å­¦è¿ç®—å¯ä»¥ä½¿ç”¨ TensorFlow æ”¯æ’‘ã€‚
* **åˆå§‹åŒ–å˜é‡**ï¼ŒÂ ç¼–è¯‘é¢„å…ˆå®šä¹‰çš„å˜é‡   
* **åˆ›å»º session**ï¼ŒÂ è¿™æ˜¯ç¥å¥‡çš„å¼€å§‹çš„åœ°æ–¹Â ï¼  
* **åœ¨ session ä¸­è¿è¡Œå›¾**ï¼ŒÂ ç¼–è¯‘å›¾å½¢è¢«ä¼ é€’åˆ° session ï¼Œå®ƒå¼€å§‹æ‰§è¡Œå®ƒã€‚
* **å…³é—­ session**ï¼ŒÂ ç»“æŸè¿™æ¬¡ä½¿ç”¨ã€‚

TensoFlow ä¸­ä½¿ç”¨çš„æœ¯è¯­å¾ˆå°‘   

```
placeholderï¼šå°†æ•°æ®è¾“å…¥å›¾å½¢çš„ä¸€ç§æ–¹æ³•
feed_dictï¼šå°†æ•°å€¼ä¼ é€’åˆ°è®¡ç®—å›¾çš„å­—å…¸
```

è®©æˆ‘ä»¬å†™ä¸€ä¸ªå°ç¨‹åºæ¥æ·»åŠ ä¸¤ä¸ªæ•°å­—ï¼

```pyhton

# import tensorflow
import tensorflow as tf

# build computational graph
a = tf.placeholder(tf.int16)
b = tf.placeholder(tf.int16)

addition = tf.add(a, b)

# initialize variables
init = tf.initialize_all_variables()

# create session and run the graph
with tf.Session() as sess:
    sess.run(init)
    print "Addition: %i" % sess.run(addition, feed_dict={a: 2, b: 3})

# close session
sess.close()
```

### <a name="MLP"></a>åœ¨ TensorFlow ä¸­å®ç°ç¥ç»ç½‘ç»œ

*æ³¨æ„ï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒçš„ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨æ·±å…¥å®æ–½ä¸­è®¨è®º `å‰é¦ˆå¤šå±‚æ„ŸçŸ¥å™¨`ã€‚*

è®©æˆ‘ä»¬è®°ä½å¯¹ç¥ç»ç½‘ç»œçš„äº†è§£ã€‚

ç¥ç»ç½‘ç»œçš„å…¸å‹å®ç°å¦‚ä¸‹ï¼š

* å®šä¹‰è¦ç¼–è¯‘çš„ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„
* å°†æ•°æ®ä¼ è¾“åˆ°æ¨¡å‹
* æ•´ä¸ªè¿è¡Œä¸­ï¼Œæ•°æ®é¦–å…ˆè¢«åˆ†æˆæ‰¹æ¬¡ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è¢«æ‘„å–ã€‚é¦–å…ˆå¯¹æ‰¹æ¬¡è¿›è¡Œé¢„å¤„ç†ï¼Œæ‰©å¢ï¼Œç„¶åé€å…¥ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ
* ç„¶åï¼Œæ¨¡å‹è¢«é€æ­¥åœ°è®­ç»ƒ
* æ˜¾ç¤ºç‰¹å®šæ•°é‡çš„æ—¶é—´æ­¥é•¿çš„ç²¾åº¦
* è®­ç»ƒåä¿å­˜æ¨¡å‹ä¾›å°†æ¥ä½¿ç”¨
* åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•æ¨¡å‹å¹¶æ£€æŸ¥å…¶è¿è¡Œæ–¹å¼

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è§£å†³äº†æˆ‘ä»¬æ·±åˆ»çš„å­¦ä¹ å®è·µä¸­çš„é—®é¢˜ -Â [è¯†åˆ«æ•°å­—]ï¼Œè®©å†æˆ‘ä»¬èŠ±ä¸€ç‚¹æ—¶é—´çœ‹çœ‹é—®é¢˜é™ˆè¿°ã€‚

ã€€ã€€æˆ‘ä»¬çš„é—®é¢˜æ˜¯å›¾åƒè¯†åˆ«ï¼Œä»¥è¯†åˆ«æ¥è‡ªç»™å®šçš„ 28Ã—28 å›¾åƒçš„æ•°å­—ã€‚Â æˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾åƒå­é›†ç”¨äºè®­ç»ƒï¼Œå…¶ä½™çš„ç”¨äºæµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ã€‚é¦–å…ˆä¸‹è½½è®­ç»ƒå’Œæµ‹è¯•æ–‡ä»¶ã€‚æ•°æ®é›†åŒ…å«æ•°æ®é›†ä¸­æ‰€æœ‰å›¾åƒçš„å‹ç¼©æ–‡ä»¶ï¼Œ train.csv å’Œ test.csv éƒ½æœ‰ç›¸åº”çš„è®­ç»ƒå’Œæµ‹è¯•å›¾åƒçš„åç§°ã€‚æ•°æ®é›†ä¸­ä¸æä¾›ä»»ä½•å…¶ä»–åŠŸèƒ½ï¼Œåªæ˜¯åŸå§‹å›¾åƒä»¥ â€œ.pngâ€ æ ¼å¼æä¾›ã€‚

ã€€ã€€å¦‚ä¹‹å‰è¯´çš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ TensorFlow æ¥åˆ›å»ºä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ã€‚Â æ‰€ä»¥é¦–å…ˆåœ¨ä½ çš„ç³»ç»Ÿä¸­å®‰è£… TensorFlow ã€‚Â è¯·å‚è€ƒÂ [å®˜æ–¹çš„å®‰è£…æŒ‡å—](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md)Â è¿›è¡Œå®‰è£…ï¼ŒæŒ‰æ‚¨çš„ç³»ç»Ÿè§„æ ¼ã€‚

æˆ‘ä»¬å°†æŒ‰ç…§ä¸Šè¿°æ¨¡æ¿

* è®©æˆ‘ä»¬æ¥Â å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—

```python

%pylab inline

import os
import numpy as np
import pandas as pd
from scipy.misc import imread
from sklearn.metrics import accuracy_score
import tensorflow as tf

```

* è®©æˆ‘ä»¬æ¥Â è®¾ç½®ä¸€ä¸ªç§å­å€¼ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ§åˆ¶æˆ‘ä»¬çš„æ¨¡å‹éšæœºæ€§

```python

# To stop potential randomness
seed = 128
rng = np.random.RandomState(seed)

```

* ç¬¬ä¸€æ­¥æ˜¯è®¾ç½®ç›®å½•è·¯å¾„ï¼Œä»¥ä¾¿ä¿ç®¡ï¼

```python

root_dir = os.path.abspath('../..')
data_dir = os.path.join(root_dir, 'data')
sub_dir = os.path.join(root_dir, 'sub')

# check for existence
os.path.exists(root_dir)
os.path.exists(data_dir)
os.path.exists(sub_dir)

```

* ç°åœ¨è®©æˆ‘ä»¬è¯»å–æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œè¿™äº›æ˜¯ .csv æ ¼å¼ï¼Œå¹¶æœ‰ä¸€ä¸ªæ–‡ä»¶åä»¥åŠç›¸åº”çš„æ ‡ç­¾

```python

train = pd.read_csv(os.path.join(data_dirï¼Œ'Train'ï¼Œ'train.csv'))
test = pd.read_csv(os.path.joinï¼ˆdata_dirï¼Œ'Test.csv'))
sample_submission = pd.read_csv(os.path.join(data_dirï¼Œ'Sample_Submission.csv'))
train.head()

```

|    | æ–‡ä»¶å | æ ‡ç­¾ |
| -- |:-----:| ---:|
|  0 | 0.png |  4  |
|  1 | 1.png |  9  |
|  2 | 2.png |  1  |
|  3 | 3.png |  7  |
|  4 | 4.png |  3  |


* è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®æ˜¯ä»€ä¹ˆæ ·å­ï¼æˆ‘ä»¬è¯»å–æˆ‘ä»¬çš„å½¢è±¡å¹¶æ˜¾ç¤ºå‡ºæ¥ã€‚

```python

img_name = rng.choice(train.filename)
filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)

img = imread(filepath, flatten=True)

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()

```

![](https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3.png)       

ä¸Šé¢çš„å›¾åƒè¡¨ç¤ºä¸º numpy æ•°ç»„ï¼Œå¦‚ä¸‹æ‰€ç¤º

![](https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one.png)       


* ä¸ºäº†æ–¹ä¾¿æ•°æ®æ“ä½œï¼Œè®©æˆ‘ä»¬Â çš„å­˜å‚¨ä½œä¸º numpy çš„é˜µåˆ—çš„æ‰€æœ‰å›¾ç‰‡

```python

temp = []
for img_name in train.filename:
    image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)
    img = imread(image_path, flatten=True)
    img = img.astype('float32')
    temp.append(img)
    
train_x = np.stack(temp)

temp = []
for img_name in test.filename:
    image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)
    img = imread(image_path, flatten=True)
    img = img.astype('float32')
    temp.append(img)
    
test_x = np.stack(temp)
```

* ç”±äºè¿™æ˜¯å…¸å‹çš„ ML é—®é¢˜ï¼Œä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹çš„æ­£ç¡®åŠŸèƒ½ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªéªŒè¯é›†ï¼Œè®©æˆ‘ä»¬ä»¥ 70:30 çš„åˆ†å‰²è®­ç»ƒé›† å’Œ éªŒè¯é›†

```python

split_size = int(train_x.shape[0]*0.7)

train_x, val_x = train_x[:split_size], train_x[split_size:]
train_y, val_y = train.label.values[:split_size], train.label.values[split_size:]

```

* æˆ‘ä»¬å®šä¹‰ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œæˆ‘ä»¬ç¨ååœ¨æˆ‘ä»¬çš„ç¨‹åºä¸­ä½¿ç”¨


```python

def dense_to_one_hot(labels_dense, num_classes=10):
    """Convert class labels from scalars to one-hot vectors"""
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
    
    return labels_one_hot

def preproc(unclean_batch_x):
    """Convert values to range 0-1"""
    temp_batch = unclean_batch_x / unclean_batch_x.max()
    
    return temp_batch

def batch_creator(batch_size, dataset_length, dataset_name):
    """Create batch with random samples and return appropriate format"""
    batch_mask = rng.choice(dataset_length, batch_size)
    
    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, 784)
    batch_x = preproc(batch_x)
    
    if dataset_name == 'train':
        batch_y = eval(dataset_name).ix[batch_mask, 'label'].values
        batch_y = dense_to_one_hot(batch_y)
        
    return batch_x, batch_y

```

* ä¸»è¦éƒ¨åˆ†ï¼Â è®©æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚Â æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç¥ç»ç½‘ç»œå…·æœ‰ 3 å±‚ï¼Œè¾“å…¥ã€éšè— å’Œ è¾“å‡ºï¼Œ è¾“å…¥å’Œè¾“å‡ºä¸­çš„ç¥ç»å…ƒæ•°ç›®æ˜¯å›ºå®šçš„ï¼Œå› ä¸ºè¾“å…¥æ˜¯æˆ‘ä»¬çš„ 28Ã—28 å›¾åƒï¼Œå¹¶ä¸”è¾“å‡ºæ˜¯è¡¨ç¤ºç±»çš„ 10Ã—1 å‘é‡ã€‚Â æˆ‘ä»¬åœ¨éšè—å±‚ä¸­å– 500 ç¥ç»å…ƒã€‚è¿™ä¸ªæ•°å­—å¯ä»¥æ ¹æ®ä½ çš„éœ€è¦å˜åŒ–ã€‚æˆ‘ä»¬æŠŠå€¼Â èµ‹ç»™Â å…¶ä½™å˜é‡ã€‚Â å¯ä»¥é˜…è¯»Â [ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†çš„æ–‡ç« ](https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/)Â ï¼Œä»¥æ›´æ·±çš„äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œã€‚

```python

### set all variables

# number of neurons in each layer

input_num_units = 28*28

hidden_num_units = 500

output_num_units = 10

# define placeholders
x = tf.placeholder(tf.float32, [None, input_num_units])
y = tf.placeholder(tf.float32, [None, output_num_units])

# set remaining variables
epochs = 5
batch_size = 128
learning_rate = 0.01

### define weights and biases of the neural network (refer this article if you don't understand the terminologies)

weights = {
    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)),
    'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))
}

biases = {
    'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)),
    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))
}

```

* ç°åœ¨åˆ›å»ºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œè®¡ç®—å›¾

```python

hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])
hidden_layer = tf.nn.relu(hidden_layer)

output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']

```

* æ­¤å¤–ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ç¥ç»ç½‘ç»œçš„æˆæœ¬

```python

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, y))

```

* è®¾ç½®ä¼˜åŒ–å™¨ï¼Œå³æˆ‘ä»¬çš„åå‘ä¼ æ’­ç®—æ³•ã€‚Â è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Â [Adam](https://arxiv.org/abs/1412.6980)Â ï¼Œè¿™æ˜¯æ¢¯åº¦ä¸‹é™ç®—æ³•çš„é«˜æ•ˆå˜ä½“ã€‚Â æœ‰åœ¨ tensorflow å¯ç”¨è®¸å¤šå…¶å®ƒä¼˜åŒ–ï¼ˆå‚ç…§Â [æ­¤å¤„](https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#optimizers)Â ï¼‰

```python

optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

```
* å®šä¹‰æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œç»“æ„åï¼Œè®©æˆ‘ä»¬æ¥Â åˆå§‹åŒ–æ‰€æœ‰çš„å˜é‡

```python

init = tf.initialize_all_variables()

```

* ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Session ï¼Œå¹¶åœ¨ Session ä¸­è¿è¡Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬è¿˜éªŒè¯æˆ‘ä»¬åˆ›å»ºçš„éªŒè¯é›†çš„æ¨¡å‹å‡†ç¡®æ€§

```python

with tf.Session() as sess:
    # create initialized variables
    sess.run(init)
    
    ### for each epoch, do:
    ###   for each batch, do:
    ###     create pre-processed batch
    ###     run optimizer by feeding batch
    ###     find cost and reiterate to minimize
    
    for epoch in range(epochs):
        avg_cost = 0
        total_batch = int(train.shape[0]/batch_size)
        for i in range(total_batch):
            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')
            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})
            
            avg_cost += c / total_batch
            
        print "Epoch:", (epoch+1), "cost =", "{:.5f}".format(avg_cost)
    
    print "\nTraining complete!"
    
    
    # find predictions on val set
    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(pred_temp, "float"))
    print "Validation Accuracy:", accuracy.eval({x: val_x.reshape(-1, 784), y: dense_to_one_hot(val_y.values)})
    
    predict = tf.argmax(output_layer, 1)
    pred = predict.eval({x: test_x.reshape(-1, 784)})
```

è¿™å°†æ˜¯ä¸Šé¢ä»£ç çš„è¾“å‡º

```python

Epoch: 1 cost = 8.93566
Epoch: 2 cost = 1.82103
Epoch: 3 cost = 0.98648
Epoch: 4 cost = 0.57141
Epoch: 5 cost = 0.44550

Training complete!
Validation Accuracy: 0.952823	

```

* éªŒè¯æˆ‘ä»¬è‡ªå·±çš„çœ¼ç›ï¼Œè®©æˆ‘ä»¬æ¥Â æƒ³è±¡å®ƒçš„é¢„è¨€

```python

img_name = rng.choice(test.filename)
filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)

img = imread(filepath, flatten=True)
 
test_index = int(img_name.split('.')[0]) - 49000

print "Prediction is: ", pred[test_index]

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()

```

```python

Prediction is:  8

```

![](https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8.png)       


* æˆ‘ä»¬çœ‹åˆ°çš„æ¨¡å‹æ€§èƒ½æ˜¯ç›¸å½“ä¸é”™ï¼Â ç°åœ¨è®©æˆ‘ä»¬Â åˆ›å»ºä¸€ä¸ªæäº¤

```python

sample_submission.filename = test.filename
 
sample_submission.label = pred

sample_submission.to_csv(os.path.join(sub_dir, 'sub01.csv'), index=False)

```

ã€€ã€€ç»ˆäºå®Œæˆäº†ï¼Â æˆ‘ä»¬åˆšåˆšåˆ›å»ºäº†è‡ªå·±çš„è®­ç»ƒç¥ç»ç½‘ç»œï¼

### <a name="Limitations-of-TensorFlow"></a>TensorFlow çš„é™åˆ¶

* å°½ç®¡ TensorFlow æ˜¯å¼ºå¤§çš„ï¼Œå®ƒä»ç„¶æ˜¯ä¸€ä¸ªä½æ°´å¹³åº“ï¼Œä¾‹å¦‚ï¼Œå®ƒå¯ä»¥è¢«è®¤ä¸ºæ˜¯æœºå™¨çº§è¯­è¨€ï¼Œä½†å¯¹äºå¤§å¤šæ•°åŠŸèƒ½ï¼Œæ‚¨éœ€è¦è‡ªå·±å»æ¨¡å—åŒ–å’Œé«˜çº§æ¥å£ï¼Œå¦‚ keras
* å®ƒä»ç„¶åœ¨ç»§ç»­å¼€å‘å’Œç»´æŠ¤ï¼Œè¿™æ˜¯å¤šä¹ˆğŸ‘å•Šï¼
* å®ƒå–å†³äºä½ çš„ç¡¬ä»¶è§„æ ¼ï¼Œé…ç½®è¶Šé«˜è¶Šå¥½
* ä¸æ˜¯æ‰€æœ‰å˜æˆè¯­è¨€èƒ½ä½¿ç”¨å®ƒçš„ API ã€‚
* TensorFlow ä¸­ä»ç„¶æœ‰å¾ˆå¤šåº“éœ€è¦æ‰‹åŠ¨å¯¼å…¥ï¼Œæ¯”å¦‚ OpenCL æ”¯æŒã€‚

ä¸Šé¢æåˆ°çš„å¤§å¤šæ•°æ˜¯åœ¨ TensorFlow å¼€å‘äººå‘˜çš„æ„¿æ™¯ï¼Œä»–ä»¬å·²ç»åˆ¶å®šäº†ä¸€ä¸ªè·¯çº¿å›¾ï¼Œè®¡åˆ’åº“æœªæ¥åº”è¯¥å¦‚ä½•å¼€å‘ã€‚

### <a name="vs-libraries"></a>TensorFlow ä¸å…¶ä»–åº“

ã€€ã€€TensorFlow å»ºç«‹åœ¨ç±»ä¼¼çš„åŸç†ï¼Œå¦‚ä½¿ç”¨æ•°å­¦è®¡ç®—å›¾è¡¨çš„ Theano å’Œ Torchï¼Œä½†æ˜¯éšç€åˆ†å¸ƒå¼è®¡ç®—çš„é¢å¤–æ”¯æŒï¼ŒTensorFlow æ›´å¥½åœ°è§£å†³å¤æ‚çš„é—®é¢˜ã€‚Â æ­¤å¤–ï¼ŒTensorFlow æ¨¡å‹çš„éƒ¨ç½²å·²ç»è¢«æ”¯æŒï¼Œè¿™ä½¿å¾—å®ƒæ›´å®¹æ˜“ç”¨äºå·¥ä¸šç›®çš„ï¼Œæ‰“å¼€ä¸€äº›å•†ä¸šçš„ä¸‰æ–¹åº“ï¼Œå¦‚ Deeplearning4j ï¼ŒH2O å’Œ Turiã€‚Â TensorFlow æœ‰ç”¨äº Pythonï¼ŒC ++ å’Œ Matlab çš„ API ã€‚Â æœ€è¿‘è¿˜å‡ºç°äº†å¯¹ Ruby å’Œ R ç­‰å…¶ä»–è¯­è¨€çš„æ”¯æŒã€‚å› æ­¤ï¼ŒTensorFlow è¯•å›¾è·å¾—é€šç”¨è¯­è¨€æ”¯æŒã€‚

### <a name="Where-to-go-from-here"></a>ä»è¿™é‡Œå»å“ªé‡Œï¼Ÿ

ã€€ã€€ä»¥ä¸Šä½ çœ‹åˆ°äº†å¦‚ä½•ç”¨ TensorFlow æ„å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œè¿™æ®µä»£ç æ˜¯ä¸ºäº†è®©äººä»¬äº†è§£å¦‚ä½•å¼€å§‹å®ç° TensorFlowã€‚Â è¦è§£å†³æ›´å¤æ‚çš„ç°å®ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œä½ å¿…é¡»åœ¨è¿™ç¯‡æ–‡ç« çš„åŸºç¡€ä¸Šåœ¨è°ƒæ•´ä¸€äº›ä»£ç æ‰è¡Œã€‚

ã€€ã€€è®¸å¤šä¸Šè¿°åŠŸèƒ½å¯ä»¥è¢«æŠ½è±¡ä¸ºç»™å‡ºæ— ç¼çš„ç«¯åˆ°ç«¯å·¥ä½œæµï¼Œå¦‚æœä½ ä½¿ç”¨ scikit-learn ï¼Œä½ å¯èƒ½çŸ¥é“ä¸€ä¸ªé«˜çº§åº“å¦‚ä½•æŠ½è±¡â€œåº•å±‚â€å®ç°ï¼Œç»™ç»ˆç«¯ç”¨æˆ·ä¸€ä¸ªæ›´å®¹æ˜“çš„ç•Œé¢ã€‚å°½ç®¡ TensorFlow å·²ç»æå–äº†å¤§å¤šæ•°å®ç°ï¼Œä½†æ˜¯ä¹Ÿæœ‰æ›´é«˜çº§çš„åº“ï¼Œå¦‚ TF-slim å’Œ TFlearnã€‚

### å‚è€ƒèµ„æº
* [TensorFlow å®˜æ–¹åº“](https://github.com/tensorflow/tensorflow) 
* Rajat Mongaï¼ˆTensorFlowæŠ€æœ¯è´Ÿè´£äººï¼‰Â [â€œTensorFlowä¸ºå¤§å®¶â€](https://youtu.be/wmw8Bbb_eIE) Â çš„è§†é¢‘
* [ä¸€ä¸ªä¸“ç”¨èµ„æºçš„ç­–åˆ’åˆ—è¡¨](https://github.com/jtoy/awesome-tensorflow/#github-projects)  

### å…³äºåŸæ–‡

æ„Ÿè°¢åŸæ–‡ä½œè€… [Faizan Shaikh](https://www.analyticsvidhya.com/blog/author/jalfaizy/) çš„åˆ†äº«ï¼Œ
è¿™ç¯‡æ–‡ç« æ˜¯åœ¨ [An Introduction to Implementing Neural Networks using TensorFlow](https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/) çš„åŸºç¡€ä¸Šåšçš„ç¿»è¯‘å’Œå±€éƒ¨è°ƒæ•´ï¼Œå¦‚æœå‘ç°ç¿»è¯‘ä¸­æœ‰ä¸å¯¹æˆ–è€…æ­§ä¹‰çš„çš„åœ°æ–¹æ¬¢è¿åœ¨ä¸‹é¢è¯„è®ºé‡Œæé—®ï¼Œæˆ‘ä¼šåŠ ä»¥ä¿®æ­£ ã€‚



<br>
è½¬è½½è¯·æ³¨æ˜ï¼š[æ½˜æŸä¿¡çš„åšå®¢](http://baixin) Â» [ä½¿ç”¨ TensorFlow å®ç°ç¥ç»ç½‘ç»œ](http://baixin.io/2016/11/neural_networks_using_TensorFlow/)  


I"`<<p>主要包括使用一维卷积神经网络(1D CNN)对安装在远程风机的高速轴承中的现场传感器采集到的时间序列数据通过短时傅里叶变化之后得到的频谱峰度（Kurtosis Spectogram）进行分类，得到每个样品的类别：中等寿命级（预期寿命大于15天的轴承——状态良好）以及短寿命轴承（预期寿命小于15天的轴承——状态不良）。</p>

<p><a href="https://www.kaggle.com/code/luishpinto/wind-turbine-high-speed-bearing-prognosis">原文链接：Wind Turbine High Speed Bearing Prognosis Kaggle</a></p>

<h1 id="1-问题描述">1. 问题描述</h1>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220141757.png" alt="轴承寿命预测" /></p>

<p>本文展示了使用振动监测传感器的原始数据来预测轴承的RUL（剩余使用寿命）的新方法，这种方法也可以用于其他类型的机器元件，如齿轮、联轴器等剩余寿命的预测。</p>

<p>本例中使用的数据是由安装在一个远程风力涡轮机的高速轴承上的现场传感器记录的。
该轴承是齿轮箱的一部分，负责转子和发电机之间的耦合，特别是在高速轴上（发电机一侧）。</p>

<p>该数据可以通过以下方式访问：</p>

<ol>
  <li><a href="https://github.com/mathworks/WindTurbineHighSpeedBearingPrognosis-Data">WindTurbineHighSpeedBearingPrognosis-Data</a></li>
</ol>

<p>记录的变量是传感器在30天内测得的加速度（单位：g），每天6秒。</p>

<h1 id="2-技术背景">2. 技术背景</h1>

<p>该方法是基于对50个样本中的每个样本的Kurtosis Spectogram（频谱峰度）的计算，并使用1D-CNN–一维卷积神经网络将每个样本划分为两个RUL等级。中等预期寿命类，代表轴承的预期寿命大于15天（状况良好）。</p>

<ol>
  <li>中等预期寿命的类别：寿命大于15天（状况良好）。</li>
  <li>短预期寿命类别，代表轴承的寿命期望值小于15天（状况不佳）。</li>
</ol>

<p>基于这个假设，寿命最短的15个被标记为短寿命类，而所有剩余的被标记为中寿命类。</p>

<h1 id="数据处理流程">数据处理流程</h1>

<h2 id="导入包">导入包</h2>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

import matplotlib
matplotlib.rcParams['mathtext.fontset'] = 'stix' 
matplotlib.rcParams['font.family'] = 'sans-serif'
matplotlib.rcParams['font.size'] = 10

from scipy.io import loadmat # scipy加载mat文件
from scipy.signal import stft # scipy的短时傅里叶变换
from scipy.stats import kurtosis # kurtosis表示峰度，峰度是统计学中的一个概念，用来描述某个分布的峰值的陡峭程度

from mpl_toolkits.mplot3d import Axes3D

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split

from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.utils import *
</code></pre>

<h2 id="定义混淆矩阵可视化函数">定义混淆矩阵可视化函数</h2>

<pre><code class="language-python">def plotConfusionMatrix(dtrue,dpred,classes,\
                        cmap = plt.cm.Blues,bsize = 1.0): # 混淆矩阵可视化函数,dtrue表示真实值,dpred表示预测值,classes表示类别,cmap表示颜色,bsize表示图像大小
  
    cm = confusion_matrix(dtrue,dpred,normalize = 'true') # 混淆矩阵,normalize = 'true'表示归一化
  
    fig,ax = plt.subplots(figsize = (np.shape(classes)[0] * 1.25 * bsize,\
                                     np.shape(classes)[0] * 1.25 * bsize))
  
    im = ax.imshow(cm,interpolation = 'nearest',cmap = cmap) # interpolation = 'nearest'表示插值方式,nearest表示最近邻插值,cm表示混淆矩阵,cmap表示颜色
  
    ax.set(xticks = np.arange(cm.shape[1]),\
           yticks = np.arange(cm.shape[0]),\
           xticklabels = classes,\
           yticklabels = classes,\
           ylabel = 'True Efficiency',\
           xlabel = 'Predicted Efficiency')
  
    plt.setp(ax.get_xticklabels(),rotation = 90,ha = 'right',\
             rotation_mode = 'anchor') # ha表示水平对齐方式,rotation_mode表示旋转模式，anchor表示锚点;setp表示设置属性

    fmt = '.2f' # 保留两位小数

    thresh = cm.max() / 2.0 
  
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j,i,format(cm[i,j],fmt),ha = 'center',va = 'center',\
                    color = 'white' if cm[i,j] &gt; thresh else 'black') # ha表示水平对齐方式,va表示垂直对齐方式,j表示列,i表示行
  
    fig.tight_layout()
  
    return ax
</code></pre>

<h2 id="查看数据">查看数据</h2>

<p>扫描频率为97656HZ，采样的总共时长为6s，所以采样点的个数为</p>

<pre><code class="language-python">fname = !ls './input/data'
fname = np.asarray(fname)

df = []

for i in fname:
    df.append(loadmat('./input/data/' + i)['vibration'].flatten())# loadmat表示加载mat文件,flatten表示降维
    
df = np.asarray(df) # 转换为数组

df.shape[0]

</code></pre>

<p>输出结果为：</p>

<pre><code class="language-console">50 # 表示样本数量
</code></pre>

<p>查看采样频率</p>

<pre><code class="language-python">fs = int(df.shape[1] / 6.0) # 采样频率
t = np.linspace(0.0,6.0,df.shape[1]) # df.shape[1]表示df的第二维度的长度,即采样点数；t表示一个周期内，每个采样点的时间;

print('Scan frequency: {:,d} Hz'.format(fs)) # {:,d}表示以逗号分隔的十进制整数,scan frequency表示扫描频率
</code></pre>

<p>输出结果为：</p>
<pre><code class="language-console">Scan frequency: 97,656 Hz
</code></pre>

<p>下图显示了加速度的测量值（单位：g），正如可以注意到的那样，加速度的振幅在时域上变化明显(x轴表示时间，每天6秒，50天)</p>

<pre><code class="language-python">plt.subplots(figsize = (12.0,6.0))
for i in range(df.shape[0]):
    plt.plot(t + i * 6.0,df[i],color = 'black',lw = 0.25) 

plt.xlabel('Time (in s): sample = 50 days in total, 6 seconds per day')
plt.ylabel('Acceleration (in g)')    
plt.show()
</code></pre>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220145445.png" alt="加速度振幅图" /></p>

<p>尽管加速度有明显的变化，记录的数据数量（6 x 97,656 = 
每天585,936个记录；总共29,286,800个）很大，再加上 测量的非同步条件，使得使用传统的神经网络来对轴承状况进行分类是不可行的。</p>

<p>这个问题需要一个不同的方法来将正弦波的时域变量转化为非周期性变量，从而使区分RUL等级成为可能。</p>

<h2 id="kurtosis">Kurtosis</h2>

<p>这个新的变量是通过短时傅里叶变换计算的Kurtosis，如下图所示的三维图。可以注意到，在正常情况下，Kurtosis是非常稳定的，无论频率如何变化(例如前五个样本)，但当异常的运行条件导致数据偏离正态分布时，则Kurtosis趋于变大。</p>

<pre><code class="language-python">f = []
fft = []

wnd = 127

for i in range(df.shape[0]):
    u,v,w = stft(df[i],fs,nperseg = wnd,noverlap = int(0.8 * wnd),nfft = int(2.0 * wnd)) 
    # stft表示短时傅里叶变换,fs表示采样频率;nperseg表示每段的长度,
    # noverlap表示重叠的长度,nfft表示fft的长度
    # u表示频率,v表示时域,w表示频谱
    f.append(u)
    fft.append(kurtosis(np.abs(w),fisher = False,axis = 1)) # 对频谱取绝对值,然后计算峰度
    # fisher表示是否使用Fisher标准化,axis = 1表示沿着第二维度计算峰度

f = np.asarray(f) # asarray表示将输入转换为数组,f表示频率
fft = np.asarray(fft)

fftn = (fft - fft.min()) / (fft.max() - fft.min()) # 归一化,n表示归一化后的频谱

fftn = np.asarray(fftn)
n = np.ones_like(f[0])# ones_like表示返回与输入形状相同的数组,数组元素为1
fig = plt.figure(figsize = (10.0,10.0))
ax = plt.axes(projection = '3d')
ax.view_init(30,225)
for i in range(f.shape[0]):
    ax.plot(f[i] / 1.0e3,i * n,fftn[i],color = 'black',linewidth = 0.50) #  / 1.0e3表示将频率转换为kHz

ax.set_xlabel('Frequency (kHz)')
ax.set_ylabel('Sample')
ax.set_zlabel('Kurtosis')
plt.show()
</code></pre>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220150240.png" alt="频谱峰度图" /></p>

<h2 id="模型训练">模型训练</h2>

<h3 id="准备模型">准备模型</h3>
<p>Kurtosis被用作1D-CNN的输入(变量x)，而与两个RUL等级相关的标签则通过变量y–中寿命期望值类（y = 0）用于前35个样本，而短寿命预期类（y = 1）用于最后15个样本。
y被转换为分类格式，以适应神经网络的输出格式。</p>

<p>1D-CNN是通过使用Keras开源库的Sequential()函数定义的。</p>

<pre><code class="language-python">X = fftn 
X = X.reshape(-1,f.shape[1],1) # reshape表示改变数组的形状,-1表示自动计算,1表示一维，f.shape[1]表示频率的长度
y = np.zeros(X.shape[0],dtype = int)
y[-15:] = 1 # y表示标签，-15表示从后往前数第15个，都是short-life expectancy class (y = 1)

print('Input shape: {:d} samples x {:d} registers/sample'.format(X.shape[0],X.shape[1]))

label = to_categorical(y) # to_categorical表示将标签转换为one-hot编码,one-hot编码表示将标签转换为二进制向量
label
</code></pre>

<pre><code class="language-console">Input shape: 50 samples x 128 registers/sample
</code></pre>

<pre><code class="language-python">mdl = Sequential() # Sequential表示顺序模型
mdl.add(Conv1D(100,6,activation = 'relu',\
               input_shape = (f.shape[1],1))) # Conv1D表示一维卷积层,100表示卷积核的个数,6表示卷积核的大小,activation表示激活函数
mdl.add(Conv1D(100,6,activation = 'relu'))
mdl.add(MaxPooling1D(3))
mdl.add(Conv1D(160,6,activation = 'relu'))
mdl.add(Conv1D(160,6,activation = 'relu'))
mdl.add(GlobalAveragePooling1D())
mdl.add(Dropout(0.5))
mdl.add(Dense(2,activation = 'softmax'))

print(mdl.summary())
</code></pre>

<p>输出结果如下：</p>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220150743.png" alt="模型总结" /></p>

<h3 id="训练模型">训练模型</h3>

<pre><code class="language-python">mdl.compile(loss = 'categorical_crossentropy',\
            optimizer = 'adam',metrics = ['accuracy']) # compile表示编译模型,loss表示损失函数,optimizer表示优化器,metrics表示评估模型的指标
</code></pre>

<p>该模型在50%的样本上进行了训练–需要注意的是，该数据集非常有限，只有50个样本,尽管每个样本有大量的记录。</p>

<p>训练是基于1,000个epochs–这是为了让模型有一个良好的收敛。</p>

<p>代价矩阵（变量cw）被用来影响分类结果并避免与错误分类相关的错误。</p>

<p>当遇到很难决策的时候，<strong>将中等寿命的轴承归类为短寿命轴承</strong>，并将决定权交给维修专家，让维修专家来决定，而不是错误地将短寿命的轴承错误分类并导致机组故障。</p>

<pre><code class="language-python">batch,epoch = 32,1000 # batch表示每次训练的样本数,epoch表示训练的轮数
cw = {0: 5.0,1:75.0} # cw表示类别权重

Xtrain,Xtest,ytrain,ytest = train_test_split(X,label,\
                                             random_state = 21,\
                                             test_size = 0.50)
# train_test_split表示将数据集分为训练集和测试集,random_state表示随机数种子,test_size表示测试集的比例为50%

hist = mdl.fit(Xtrain,ytrain,batch_size = batch,\
               epochs = epoch,validation_split = 0.2,verbose = 0,\
               class_weight = cw)
# fit表示训练模型,batch_size表示每次训练的样本数,epochs表示训练的轮数,validation_split表示验证集的比例,verbose表示日志显示,0表示不显示
</code></pre>

<p>训练之后，画出accracy和loss随着训练次数的变化图。我们认为，接近1的正确率说明训练收敛情况良好。</p>

<pre><code class="language-python">plt.subplots(1,2,figsize = (9.0,4.5),sharex = True) # sharex表示共享x轴
plt.subplot(1,2,1)
plt.plot(hist.epoch,hist.history['accuracy'],\
         color = 'black',lw = 2.50)  
# hist.epoch表示训练的轮数,hist.history['accuracy']表示训练集的准确率,可以看到随着训练的轮数增加,训练集的准确率也在增加
plt.ylabel('1D-CNN Accuracy')
plt.xlabel('Epoch')
plt.subplot(1,2,2)
plt.plot(hist.epoch,hist.history['loss'],\
         color = 'pink',lw = 2.50)
plt.ylabel('1D-CNN Loss')
plt.xlabel('Epoch')
plt.tight_layout()
plt.show()
</code></pre>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220151615.png" alt="accuracy and loss" /></p>

<p>可以发现，模型的准确率高到90%。</p>

<p>评估模型的变现：</p>

<pre><code class="language-python">print(mdl.evaluate(Xtest,ytest,verbose = 2)) # evaluate表示评估模型
</code></pre>

<p>输出结果如下：</p>

<pre><code class="language-console">1/1 - 0s - loss: 0.4079 - accuracy: 0.9200 - 28ms/epoch - 28ms/step
[0.4079207181930542, 0.9200000166893005]
</code></pre>

<p>分类报告显示了每个类的精度、召回率和f1-score的详细信息，包括模型的整体性能。</p>

<pre><code class="language-python"># print(classification_report(np.where(ytest != 0)[1],\
#                             mdl.predict_classes(Xtest)))
predict=mdl.predict(Xtest) 
classes_x=np.argmax(predict,axis=1)
print(classification_report(np.where(ytest != 0)[1],\
                            classes_x))
</code></pre>

<p>输出结果如下：</p>

<pre><code class="language-console">1/1 [==============================] - 0s 37ms/step
              precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.80      1.00      0.89         8

    accuracy                           0.92        25
   macro avg       0.90      0.94      0.91        25
weighted avg       0.94      0.92      0.92        25
</code></pre>

<p>通过下面描述的混淆矩阵，可以更直观地显示召回率：</p>

<pre><code class="language-python">plotConfusionMatrix(np.argmax(ytest,axis = 1),\
                    np.argmax(mdl.predict(Xtest),axis = 1),\
                    ['medium','short'],\
                    bsize = 1.75,cmap = 'binary')
plt.title('Accuracy (RECALL)')
plt.show()
</code></pre>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220152136.png" alt="召回率混淆矩阵" /></p>

<h1 id="附录">附录</h1>

<h2 id="深度学习评价标准">深度学习评价标准</h2>

<p><img src="https://cdn.jsdelivr.net/gh/ChanJeunlam/PicgoBed/blogs/pictures/20230220152541.png" alt="Confusion matrix" /></p>

<p>TP(a)：实际正类预测为正类的数量；FN(b)：实际正类预测为负类的数量</p>

<p>FP(c)：实际负类预测为正类的数量；TN(d)：实际负类预测为负类的数量</p>

<p>IoU交并比：</p>

\[IoU = tp/(tp+fp+fn)\]

<p>Precision 精确率（也就是查准率）:</p>

\[Precision = tp /(tp+fp)\]

<h2 id="频谱峰度kurtosis-spectogram">频谱峰度（Kurtosis Spectogram）</h2>

<h2 id="1d-cnn">1D CNN</h2>
:ET